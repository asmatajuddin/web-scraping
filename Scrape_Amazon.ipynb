{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Scrape Amazon"
      ],
      "metadata": {
        "id": "D4mnijnxaUrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the practical applications of web scraping could be:\n",
        "\n",
        "Gathering resume of candidates with a specific skill,\n",
        "Extracting tweets from twitter with specific hashtags,\n",
        "Lead generation in marketing,\n",
        "Scraping product details and reviews from e-commerce websites such as Amazon, the focus of this tutorial\n",
        "Apart from the above use-cases, web scraping is widely used in natural language processing for extracting text from the websites for training a deep learning model.\n",
        "\n",
        "Potential Challenges of Web Scraping\n",
        "\n",
        "One of the challenges you would come across while scraping information from websites is the various structures of websites. Meaning, the templates of websites will differ and will be unique; hence, generalizing across websites could be a challenge.\n",
        "\n",
        "Another challenge could be longevity. Since the web developers keep updating their websites, you cannot certainly rely on one scraper for too long. Even though the modifications might be minor, but they still might create a hindrance for you while fetching the data.\n",
        "\n",
        "Hence, to address the above challenges, there could be various possible solutions. One would be to follow continuous integration & development (CI/CD) and constant maintenance as the website modifications would be dynamic.\n",
        "\n",
        "Another more realistic approach is to use Application Programming Interfaces (APIs) offered by various websites & platforms. For example, Facebook and twitter provide you API's specially designed for developers who want to experiment with their data or would like extract information to let's say related to all friends & mutual friends and draw a connection graph of it. The format of the data when using APIs is different from usual web scraping i.e., JSON or XML, while in standard web scraping, you mainly deal with data in HTML format.\n",
        "\n",
        "What is Beautiful Soup?\n",
        "\n",
        "Beautiful Soup is a pure Python library for extracting structured data from a website. It allows you to parse data from HTML and XML files. It acts as a helper module and interacts with HTML in a similar and better way as to how you would interact with a web page using other available developer tools.\n",
        "\n",
        "It usually saves programmers hours or days of work since it works with your favorite parsers like lxml and html5lib to provide organic Python ways of navigating, searching, and modifying the parse tree.\n",
        "\n",
        "Another powerful and useful feature of beautiful soup is its intelligence to convert the documents being fetched to Unicode and outgoing documents to UTF-8. As a developer, you do not have to take care of that unless the document intrinsic doesn't specify an encoding or Beautiful Soup is unable to detect one.\n",
        "\n",
        "It is also considered to be faster when compared to other general parsing or scraping techniques."
      ],
      "metadata": {
        "id": "eKssttmbaavo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install beautifulsoup4\n"
      ],
      "metadata": {
        "id": "QALS6wF2ac_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.ticker as ticker\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n"
      ],
      "metadata": {
        "id": "sNvNYF17aes7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scraping the Amazon Best Selling Books\n",
        "\n",
        "This URL that you are going to scrape is the following: https://www.amazon.in/gp/bestsellers/books/. The page argument can be modified to access data for each page. Hence, to access all the pages you will need to loop through all the pages to get the necessary dataset, but first, you need to find out the number of pages from the website.\n",
        "\n",
        "To connect to the URL and fetch the HTML content following things are required:\n",
        "\n",
        "Define a get_data function which will input the page numbers as an argument,\n",
        "Define a user-agent which will help in bypassing the detection as a scraper,\n",
        "Specify the URL to requests.get and pass the user-agent header as an argument,\n",
        "Extract the content from requests.get,\n",
        "Scrape the specified page and assign it to soup variable,\n",
        "Next and the important step is to identify the parent tag under which all the data you need will reside. The data that you are going to extract is:\n",
        "\n",
        "Book Name\n",
        "Author\n",
        "Rating\n",
        "Customers Rated\n",
        "Price\n",
        "The below image shows where the parent tag is located, and when you hover over it, all the required elements are highlighted."
      ],
      "metadata": {
        "id": "Zf6dihtvahge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_pages = 2\n",
        "\n",
        "def get_data(pageNo):\n",
        "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "    r = requests.get('https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_'+str(pageNo)+'?ie=UTF8&pg='+str(pageNo), headers=headers)#, proxies=proxies)\n",
        "    content = r.content\n",
        "    soup = BeautifulSoup(content)\n",
        "    #print(soup)\n",
        "\n",
        "    alls = []\n",
        "    for d in soup.findAll('div', attrs={'class':'a-section a-spacing-none aok-relative'}):\n",
        "        #print(d)\n",
        "        name = d.find('span', attrs={'class':'zg-text-center-align'})\n",
        "        n = name.find_all('img', alt=True)\n",
        "        #print(n[0]['alt'])\n",
        "        author = d.find('a', attrs={'class':'a-size-small a-link-child'})\n",
        "        rating = d.find('span', attrs={'class':'a-icon-alt'})\n",
        "        users_rated = d.find('a', attrs={'class':'a-size-small a-link-normal'})\n",
        "        price = d.find('span', attrs={'class':'p13n-sc-price'})\n",
        "\n",
        "        all1=[]\n",
        "\n",
        "        if name is not None:\n",
        "            #print(n[0]['alt'])\n",
        "            all1.append(n[0]['alt'])\n",
        "        else:\n",
        "            all1.append(\"unknown-product\")\n",
        "\n",
        "        if author is not None:\n",
        "            #print(author.text)\n",
        "            all1.append(author.text)\n",
        "        elif author is None:\n",
        "            author = d.find('span', attrs={'class':'a-size-small a-color-base'})\n",
        "            if author is not None:\n",
        "                all1.append(author.text)\n",
        "            else:\n",
        "                all1.append('0')\n",
        "\n",
        "        if rating is not None:\n",
        "            #print(rating.text)\n",
        "            all1.append(rating.text)\n",
        "        else:\n",
        "            all1.append('-1')\n",
        "\n",
        "        if users_rated is not None:\n",
        "            #print(price.text)\n",
        "            all1.append(users_rated.text)\n",
        "        else:\n",
        "            all1.append('0')\n",
        "\n",
        "        if price is not None:\n",
        "            #print(price.text)\n",
        "            all1.append(price.text)\n",
        "        else:\n",
        "            all1.append('0')\n",
        "        alls.append(all1)\n",
        "    return alls\n"
      ],
      "metadata": {
        "id": "Ozkxt7amal_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for i in range(1, no_pages+1):\n",
        "    results.append(get_data(i))\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "df = pd.DataFrame(flatten(results),columns=['Book Name','Author','Rating','Customers_Rated', 'Price'])\n",
        "df.to_csv('amazon_products.csv', index=False, encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "Qm05oKxIanPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"amazon_products.csv\")\n"
      ],
      "metadata": {
        "id": "uSJGpNv0apNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "xZ4Kofcuaqqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(61)\n"
      ],
      "metadata": {
        "id": "4FGOwPsEatAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Rating'] = df['Rating'].apply(lambda x: x.split()[0])\n"
      ],
      "metadata": {
        "id": "QR39TQ5UauD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Rating'] = pd.to_numeric(df['Rating'])\n"
      ],
      "metadata": {
        "id": "hGYUfOZ1av82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Price\"] = df[\"Price\"].str.replace('â‚¹', '')\n"
      ],
      "metadata": {
        "id": "HN-Acv5ia4sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Price\"] = df[\"Price\"].str.replace(',', '')\n"
      ],
      "metadata": {
        "id": "QVNF4G18a5ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Price'] = df['Price'].apply(lambda x: x.split('.')[0])\n"
      ],
      "metadata": {
        "id": "MgRRI_cDa7Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Price'] = df['Price'].astype(int)\n"
      ],
      "metadata": {
        "id": "Wc1bSfzfa8z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Customers_Rated\"] = df[\"Customers_Rated\"].str.replace(',', '')\n"
      ],
      "metadata": {
        "id": "ecmY1dIRa-qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Customers_Rated'] = pd.to_numeric(df['Customers_Rated'], errors='ignore')\n"
      ],
      "metadata": {
        "id": "9hfb4rTnbAJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "hE6_X-llbBss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes\n"
      ],
      "metadata": {
        "id": "YnFVlQW3bDEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.replace(str(0), np.nan, inplace=True)\n",
        "df.replace(0, np.nan, inplace=True)\n"
      ],
      "metadata": {
        "id": "8JU2tYMEbEnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_nan = len(df) - df.count()\n"
      ],
      "metadata": {
        "id": "9zwNB0atbGWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_nan\n"
      ],
      "metadata": {
        "id": "PYPD7O-ZbHnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n"
      ],
      "metadata": {
        "id": "Qc_-NPXkbJCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.sort_values([\"Price\"], axis=0, ascending=False)[:15]\n"
      ],
      "metadata": {
        "id": "wX7eWeLcbK8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.models import ColumnDataSource\n",
        "from bokeh.transform import dodge\n",
        "import math\n",
        "from bokeh.io import curdoc\n",
        "curdoc().clear()\n",
        "from bokeh.io import push_notebook, show, output_notebook\n",
        "from bokeh.layouts import row\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.transform import factor_cmap\n",
        "from bokeh.models import Legend\n",
        "output_notebook()\n"
      ],
      "metadata": {
        "id": "BJEhDtXtbPHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = figure(x_range=data.iloc[:,1], plot_width=800, plot_height=550, title=\"Authors Highest Priced Book\", toolbar_location=None, tools=\"\")\n",
        "\n",
        "p.vbar(x=data.iloc[:,1], top=data.iloc[:,4], width=0.9)\n",
        "\n",
        "p.xgrid.grid_line_color = None\n",
        "p.y_range.start = 0\n",
        "p.xaxis.major_label_orientation = math.pi/2\n"
      ],
      "metadata": {
        "id": "bMg4bEB4bPKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show(p)\n"
      ],
      "metadata": {
        "id": "UbKKBT2vbTns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[df['Customers_Rated'] > 1000]\n"
      ],
      "metadata": {
        "id": "MEBQIGTObVOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sort_values(['Rating'],axis=0, ascending=False)[:15]\n"
      ],
      "metadata": {
        "id": "lCl-g8MZbXsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = figure(x_range=data.iloc[:,0], plot_width=800, plot_height=600, title=\"Top Rated Books with more than 1000 Customers Rating\", toolbar_location=None, tools=\"\")\n",
        "\n",
        "p.vbar(x=data.iloc[:,0], top=data.iloc[:,2], width=0.9)\n",
        "\n",
        "p.xgrid.grid_line_color = None\n",
        "p.y_range.start = 0\n",
        "p.xaxis.major_label_orientation = math.pi/2\n"
      ],
      "metadata": {
        "id": "NcQQ38vYbcrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show(p)\n"
      ],
      "metadata": {
        "id": "rPUBcgeqbhLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = figure(x_range=data.iloc[:,1], plot_width=800, plot_height=600, title=\"Top Rated Books with more than 1000 Customers Rating\", toolbar_location=None, tools=\"\")\n",
        "\n",
        "p.vbar(x=data.iloc[:,1], top=data.iloc[:,2], width=0.9)\n",
        "\n",
        "p.xgrid.grid_line_color = None\n",
        "p.y_range.start = 0\n",
        "p.xaxis.major_label_orientation = math.pi/2\n"
      ],
      "metadata": {
        "id": "Yg5Ce311biMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show(p)\n"
      ],
      "metadata": {
        "id": "SKkhT-fGbjnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.sort_values([\"Customers_Rated\"], axis=0, ascending=False)[:20]\n"
      ],
      "metadata": {
        "id": "dAKGRb3Pbk_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.transform import factor_cmap\n",
        "from bokeh.models import Legend\n",
        "from bokeh.palettes import Dark2_5 as palette\n",
        "import itertools\n",
        "from bokeh.palettes import d3\n",
        "#colors has a list of colors which can be used in plots\n",
        "colors = itertools.cycle(palette)\n",
        "\n",
        "palette = d3['Category20'][20]\n"
      ],
      "metadata": {
        "id": "zMLfcftqbms1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_cmap = factor_cmap('Author', palette=palette,\n",
        "                         factors=data[\"Author\"])\n"
      ],
      "metadata": {
        "id": "q9Y9IZUDbpJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = figure(plot_width=700, plot_height=700, title = \"Top Authors: Rating vs. Customers Rated\")\n",
        "p.scatter('Rating','Customers_Rated',source=data,fill_alpha=0.6, fill_color=index_cmap,size=20,legend='Author')\n",
        "p.xaxis.axis_label = 'RATING'\n",
        "p.yaxis.axis_label = 'CUSTOMERS RATED'\n",
        "p.legend.location = 'top_left'\n"
      ],
      "metadata": {
        "id": "cMnZZJVGbqdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show(p)\n"
      ],
      "metadata": {
        "id": "bvLLXqc8brsQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}