{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Web Scraping using Python (and Beautiful Soup)"
      ],
      "metadata": {
        "id": "Zx8vbOR7BPzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web. Whether you are a data scientist, engineer, or anybody who analyzes large amounts of datasets, the ability to scrape data from the web is a useful skill to have. Let's say you find data from the web, and there is no direct way to download it, web scraping using Python is a skill you can use to extract the data into a useful form that can be imported.\n",
        "\n",
        "In this tutorial, you will learn about the following:\n",
        "\n",
        "Data extraction from the web using Python's Beautiful Soup module\n",
        "Data manipulation and cleaning using Python's Pandas library\n",
        "Data visualization using Python's Matplotlib library\n",
        "The dataset used in this tutorial was taken from a 10K race that took place in Hillsboro, OR on June 2017. Specifically, you will analyze the performance of the 10K runners and answer questions such as:\n",
        "\n",
        "What was the average finish time for the runners?\n",
        "Did the runners' finish times follow a normal distribution?\n",
        "Were there any performance differences between males and females of various age groups?\n",
        "Web Scraping using Beautiful Soup\n",
        "\n",
        "Using Jupyter Notebook, you should start by importing the necessary modules (pandas, numpy, matplotlib.pyplot, seaborn). If you don't have Jupyter Notebook installed, I recommend installing it using the Anaconda Python distribution which is available on the internet. To easily display the plots, make sure to include the line %matplotlib inline as shown below."
      ],
      "metadata": {
        "id": "1dJpfMoXBRZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "kKgt_ZGrBVvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform web scraping, you should also import the libraries shown below. The urllib.request module is used to open URLs. The Beautiful Soup package is used to extract data from html files. The Beautiful Soup library's name is bs4 which stands for Beautiful Soup, version 4."
      ],
      "metadata": {
        "id": "DfY8lElHBW-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n"
      ],
      "metadata": {
        "id": "bvzstgmwBZwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://www.hubertiming.com/results/2017GPTR10K\"\n",
        "html = urlopen(url)\n"
      ],
      "metadata": {
        "id": "sCLA0d30BZ2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(html, 'lxml')\n",
        "type(soup)\n"
      ],
      "metadata": {
        "id": "6_Tdwht6BdJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs4.BeautifulSoup\n"
      ],
      "metadata": {
        "id": "8Fg6QYjjBfXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the title\n",
        "title = soup.title\n",
        "print(title)\n"
      ],
      "metadata": {
        "id": "RdXlsh5gBguj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "<title>2017 Intel Great Place to Run 10K \\ Urban Clash Games Race Results</title>\n"
      ],
      "metadata": {
        "id": "y2wrHp_4Biwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the text\n",
        "text = soup.get_text()\n",
        "#print(soup.text)\n"
      ],
      "metadata": {
        "id": "UEDWorPPBkPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('a')\n"
      ],
      "metadata": {
        "id": "Qgn943BzBl4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[<a class=\"btn btn-primary btn-lg\" href=\"/results/2017GPTR\" role=\"button\">5K</a>,\n",
        " <a href=\"http://hubertiming.com\">Huber Timing Home</a>,\n",
        " <a href=\"#individual\">Individual Results</a>,\n",
        " <a href=\"#team\">Team Results</a>,\n",
        " <a href=\"mailto:timing@hubertiming.com\">timing@hubertiming.com</a>,\n",
        " <a href=\"#tabs-1\" style=\"font-size: 18px\">Results</a>,\n",
        " <a name=\"individual\"></a>,\n",
        " <a name=\"team\"></a>,\n",
        " <a href=\"http://www.hubertiming.com\"><img height=\"65\" src=\"/sites/all/themes/hubertiming/images/clockWithFinishSign_small.png\" width=\"50\"/>Huber Timing</a>,\n",
        " <a href=\"http://facebook.com/hubertiming\"><img src=\"/results/FB-f-Logo__blue_50.png\"/></a>]\n"
      ],
      "metadata": {
        "id": "cvBastzlBn0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_links = soup.find_all(\"a\")\n",
        "for link in all_links:\n",
        "    print(link.get(\"href\"))\n"
      ],
      "metadata": {
        "id": "mHHAGOAXBrtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/results/2017GPTR\n",
        "http://hubertiming.com/\n",
        "#individual\n",
        "#team\n",
        "mailto:timing@hubertiming.com\n",
        "#tabs-1\n",
        "None\n",
        "None\n",
        "http://www.hubertiming.com/\n",
        "http://facebook.com/hubertiming/\n"
      ],
      "metadata": {
        "id": "Xe4WsPLSBtCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 10 rows for sanity check\n",
        "rows = soup.find_all('tr')\n",
        "print(rows[:10])\n"
      ],
      "metadata": {
        "id": "YgBrtb7iBwTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in rows:\n",
        "    row_td = row.find_all('td')\n",
        "print(row_td)\n",
        "type(row_td)\n"
      ],
      "metadata": {
        "id": "ka0FD5-ZBy2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str_cells = str(row_td)\n",
        "cleantext = BeautifulSoup(str_cells, \"lxml\").get_text()\n",
        "print(cleantext)\n"
      ],
      "metadata": {
        "id": "B3Y-b8FoB7Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "list_rows = []\n",
        "for row in rows:\n",
        "    cells = row.find_all('td')\n",
        "    str_cells = str(cells)\n",
        "    clean = re.compile('<.*?>')\n",
        "    clean2 = (re.sub(clean, '',str_cells))\n",
        "    list_rows.append(clean2)\n",
        "print(clean2)\n",
        "type(clean2)\n"
      ],
      "metadata": {
        "id": "JxbuyhklB_qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list_rows)\n",
        "df.head(10)\n"
      ],
      "metadata": {
        "id": "FM2QHcInCCKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df[0].str.split(',', expand=True)\n",
        "df1.head(10)\n"
      ],
      "metadata": {
        "id": "5A35374sCEW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[0] = df1[0].str.strip('[')\n",
        "df1.head(10)\n"
      ],
      "metadata": {
        "id": "FaECuJxfCF4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_labels = soup.find_all('th')\n"
      ],
      "metadata": {
        "id": "86qwATSYCHfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_header = []\n",
        "col_str = str(col_labels)\n",
        "cleantext2 = BeautifulSoup(col_str, \"lxml\").get_text()\n",
        "all_header.append(cleantext2)\n",
        "print(all_header)\n"
      ],
      "metadata": {
        "id": "gPudLcpoCJij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(all_header)\n",
        "df2.head()\n"
      ],
      "metadata": {
        "id": "cBsGgDXVCK5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df2[0].str.split(',', expand=True)\n",
        "df3.head()\n"
      ],
      "metadata": {
        "id": "sVyPX_bZCNLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [df3, df1]\n",
        "\n",
        "df4 = pd.concat(frames)\n",
        "df4.head(10)\n"
      ],
      "metadata": {
        "id": "qzcxZ1avCOpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = df4.rename(columns=df4.iloc[0])\n",
        "df5.head()\n"
      ],
      "metadata": {
        "id": "S08JsIRXCQlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5.info()\n",
        "df5.shape\n"
      ],
      "metadata": {
        "id": "LtYE_1e5CS0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df6 = df5.dropna(axis=0, how='any')\n"
      ],
      "metadata": {
        "id": "hEvb9PuyCUnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7 = df6.drop(df6.index[0])\n",
        "df7.head()\n"
      ],
      "metadata": {
        "id": "4IC9Cl97CYQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7.rename(columns={'[Place': 'Place'},inplace=True)\n",
        "df7.rename(columns={' Team]': 'Team'},inplace=True)\n",
        "df7.head()\n"
      ],
      "metadata": {
        "id": "1OMNE3GdCaHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7['Team'] = df7['Team'].str.strip(']')\n",
        "df7.head()\n"
      ],
      "metadata": {
        "id": "aGF2V0uZCbvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_list = df7[' Chip Time'].tolist()\n",
        "\n",
        "# You can use a for loop to convert 'Chip Time' to minutes\n",
        "\n",
        "time_mins = []\n",
        "for i in time_list:\n",
        "    h, m, s = i.split(':')\n",
        "    math = (int(h) * 3600 + int(m) * 60 + int(s))/60\n",
        "    time_mins.append(math)\n",
        "#print(time_mins)\n"
      ],
      "metadata": {
        "id": "LOGGxUd3CdWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7['Runner_mins'] = time_mins\n",
        "df7.head()\n"
      ],
      "metadata": {
        "id": "X61HI3PKCfbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7.describe(include=[np.number])\n"
      ],
      "metadata": {
        "id": "spnHPkh6ChB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7.boxplot(column='Runner_mins')\n",
        "plt.grid(True, axis='y')\n",
        "plt.ylabel('Chip Time')\n",
        "plt.xticks([1], ['Runners'])\n"
      ],
      "metadata": {
        "id": "uG7S2dV8CiiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "([<matplotlib.axis.XTick at 0x570dd106d8>],\n",
        " <a list of 1 Text xticklabel objects>)\n"
      ],
      "metadata": {
        "id": "-_xaVQ9sCkcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df7['Runner_mins']\n",
        "ax = sns.distplot(x, hist=True, kde=True, rug=False, color='m', bins=25, hist_kws={'edgecolor':'black'})\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ALO5I6ZQCovs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_fuko = df7.loc[df7[' Gender']==' F']['Runner_mins']\n",
        "m_fuko = df7.loc[df7[' Gender']==' M']['Runner_mins']\n",
        "sns.distplot(f_fuko, hist=True, kde=True, rug=False, hist_kws={'edgecolor':'black'}, label='Female')\n",
        "sns.distplot(m_fuko, hist=False, kde=True, rug=False, hist_kws={'edgecolor':'black'}, label='Male')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "icX_q1gBCpib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "<matplotlib.legend.Legend at 0x570e301fd0>\n"
      ],
      "metadata": {
        "id": "HgAqPiJECrTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_stats = df7.groupby(\" Gender\", as_index=True).describe()\n",
        "print(g_stats)\n"
      ],
      "metadata": {
        "id": "6zXeeHupCtOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7.boxplot(column='Runner_mins', by=' Gender')\n",
        "plt.ylabel('Chip Time')\n",
        "plt.suptitle(\"\")\n"
      ],
      "metadata": {
        "id": "so3XyD7OCuv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "orPk8xKhCxtz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}